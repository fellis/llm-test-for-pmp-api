{
  "profiles": {
    "coding": {
      "model": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ",
      "max_model_len": 32768,
      "gpu_memory_utilization": 0.9,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "qwen3_xml",
      "backend_model_id": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ"
    },
    "coding-40k": {
      "model": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ",
      "max_model_len": 40960,
      "gpu_memory_utilization": 0.9,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "qwen3_xml",
      "backend_model_id": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ"
    },
    "coding-v2": {
      "model": "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ",
      "quantization": "awq",
      "max_model_len": 20480,
      "gpu_memory_utilization": 0.95,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "hermes",
      "backend_model_id": "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ"
    },
    "coding-legacy": {
      "model": "Qwen/Qwen2.5-Coder-14B-Instruct-AWQ",
      "quantization": "awq",
      "max_model_len": 32768,
      "gpu_memory_utilization": 0.9,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "hermes",
      "backend_model_id": "Qwen/Qwen2.5-Coder-14B-Instruct-AWQ"
    },
    "chat": {
      "model": "mistralai/Mistral-7B-Instruct-v0.2",
      "max_model_len": 8192,
      "gpu_memory_utilization": 0.85,
      "backend_model_id": "mistralai/Mistral-7B-Instruct-v0.2"
    },
    "instruct": {
      "model": "Qwen/Qwen2.5-32B-Instruct-AWQ",
      "quantization": "awq",
      "max_model_len": 6000,
      "gpu_memory_utilization": 0.9,
      "tool_call_parser": "hermes",
      "backend_model_id": "Qwen/Qwen2.5-32B-Instruct-AWQ"
    },
    "coding-48k": {
      "model": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ",
      "max_model_len": 49152,
      "gpu_memory_utilization": 0.9,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "qwen3_xml",
      "backend_model_id": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ"
    },
    "devstral": {
      "model": "cyankiwi/Devstral-Small-2-24B-Instruct-2512-AWQ-4bit",
      "max_model_len": 65536,
      "gpu_memory_utilization": 0.92,
      "kv_cache_dtype": "fp8",
      "tool_call_parser": "mistral",
      "chat_template": "/app/templates/tool_chat_template_mistral_parallel.jinja",
      "backend_model_id": "cyankiwi/Devstral-Small-2-24B-Instruct-2512-AWQ-4bit"
    }
  }
}
